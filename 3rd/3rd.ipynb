{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64184432 -0.55824925  1.74428588]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "c = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "W = np.random.randn(7, 3)\n",
    "h = np.dot(c, W)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.6162792  -0.69318016  0.6572156 ]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "W = np.random.randn(7, 3)\n",
    "layer = MatMul(W)\n",
    "h = layer.forward(c)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03752053  1.1403748  -3.28505057  0.93976292  0.83512369 -0.94928567\n",
      "  -2.00258505]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul\n",
    "\n",
    "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
    "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
    "\n",
    "W_in = np.random.randn(7, 3)\n",
    "W_out = np.random.randn(3, 7)\n",
    "\n",
    "in_layer0 = MatMul(W_in)\n",
    "in_layer1 = MatMul(W_in)\n",
    "out_layer = MatMul(W_out)\n",
    "\n",
    "h0 = in_layer0.forward(c0)\n",
    "h1 = in_layer1.forward(c1)\n",
    "h = 0.5 * (h0 + h1)\n",
    "s = out_layer.forward(h)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 1 5 6]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.util import preprocess\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
     ]
    }
   ],
   "source": [
    "print(id_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context_target(corpus, window_size=1):\n",
    "    target = corpus[window_size:-window_size]\n",
    "    contexts = []\n",
    "    \n",
    "    for idx in range(window_size, len(corpus)-window_size):\n",
    "        cs = []\n",
    "        for t in range(-window_size, window_size + 1):\n",
    "            if t == 0:\n",
    "                continue\n",
    "            cs.append(corpus[idx + t])\n",
    "        contexts.append(cs)\n",
    "    \n",
    "    return np.array(contexts), np.array(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexs, target = create_context_target(corpus, window_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2]\n",
      " [1 3]\n",
      " [2 4]\n",
      " [3 1]\n",
      " [4 5]\n",
      " [1 6]]\n",
      "[1 2 3 4 1 5]\n"
     ]
    }
   ],
   "source": [
    "print(contexs)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import numpy as np\n",
    "from common.layers import MatMul, SoftmaxWithLoss\n",
    "\n",
    "class SimpleCBOW():\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
    "        \n",
    "        self.in_layer0 = MatMul(W_in)\n",
    "        self.in_layer1 = MatMul(W_in)\n",
    "        self.out_layer = MatMul(W_out)\n",
    "        self.loss_layer = SoftmaxWithLoss\n",
    "        \n",
    "        layers = [self.in_layer0, self.in_layer1, self.out_layer]\n",
    "        self.params, self.grads = [], []\n",
    "        \n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        self.word_vecs = W_in\n",
    "    \n",
    "    def forward(self, contexts, target):\n",
    "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
    "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
    "        h = (h0 + h1) * 0.5\n",
    "        score = self.out_layer.forward(h)\n",
    "        loss = self.loss_layer.forward(score, target)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ds = self.loss_layer.backward(dout)\n",
    "        da = self.out_layer.backward(ds)\n",
    "        da *= 0.5\n",
    "        self.in_layer1.backward(da)\n",
    "        self.in_layer1.backward(da)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
